{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dac6deb-2e44-4c2c-a318-2a743b23ecd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-01 20:18:22.083091: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2026-01-01 20:18:22.083368: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2026-01-01 20:18:22.162042: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2026-01-01 20:18:22.319713: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2026-01-01 20:18:23.646699: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2026-01-01 20:18:26.853306: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2026-01-01 20:18:27.139146: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2026-01-01 20:18:27.139230: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import unittest\n",
    "import tensorflow as tf\n",
    "from typing import Dict, Tuple\n",
    "import numpy as np\n",
    "from choice_learn.data import ChoiceDataset\n",
    "from choice_learn.models.simple_mnl import SimpleMNL \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f539ab87-8712-41af-9362-230da4f2716f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/Q3/DeepHalo-tf/Final/DeepHalo\n"
     ]
    }
   ],
   "source": [
    "project_root = os.path.abspath(os.getcwd())\n",
    "sys.path.insert(0, project_root)\n",
    "\n",
    "print(project_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41d00cf-706b-4807-a4b1-489bd54c9688",
   "metadata": {},
   "source": [
    "# Test with unittest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b89c5844-f0a0-4e5c-af09-93f291f14c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing DeepHaloChoiceModel package v1.0.0\n"
     ]
    }
   ],
   "source": [
    "from DeepHalo.DeepHalo_choice_learn import DeepHaloChoiceModel\n",
    "from DeepHalo.Featureless_DeepHalo import DeepHaloFeatureless2D, DeepHaloFeatureless3D\n",
    "from DeepHalo.Featured_DeepHalo import DeepHaloFeatured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6babd112-6bd4-4138-88e1-de13a9a51b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Some choices never happen in the dataset: {11, 3, 5}\n",
      "2026-01-01 20:18:27.207375: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2026-01-01 20:18:27.207494: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2026-01-01 20:18:27.207649: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2026-01-01 20:18:28.297769: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2026-01-01 20:18:28.297942: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2026-01-01 20:18:28.297957: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2026-01-01 20:18:28.298028: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2026-01-01 20:18:28.298060: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1766 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[TEST] Checking X shape in compute_batch_utility for featureless vs featured\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-01 20:18:28.863304: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      ".WARNING:root:Some choices never happen in the dataset: {11, 3, 5}\n",
      ".WARNING:root:Some choices never happen in the dataset: {11, 3, 5}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[TEST] Verifying logits are masked (very negative) for unavailable items\n",
      "\n",
      "[TEST] Checking core class matches featureless flag\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".WARNING:root:Some choices never happen in the dataset: {11, 3, 5}\n",
      ".WARNING:root:Some choices never happen in the dataset: {11, 3, 5}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[TEST] Checking permutation equivariance for featured DeepHaloChoiceModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".WARNING:root:Some choices never happen in the dataset: {11, 3, 5}\n",
      ".WARNING:root:Some choices never happen in the dataset: {11, 3, 5}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[TEST] Checking permutation equivariance for 3D featureless DeepHaloChoiceModel\n",
      "\n",
      "[TEST] Checking that DeepHaloChoiceModel inherits from SimpleMNL\n",
      "\n",
      "[TEST] Checking input and output shapes/dtypes of compute_batch_utility\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".WARNING:root:Some choices never happen in the dataset: {11, 3, 5}\n",
      ".WARNING:root:Some choices never happen in the dataset: {11, 3, 5}\n",
      ".WARNING:root:Some choices never happen in the dataset: {11, 3, 5}\n",
      ".WARNING:root:Some choices never happen in the dataset: {11, 3, 5}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[TEST] Checking permutation invariance for 2D featureless DeepHaloChoiceModel\n",
      "\n",
      "[TEST] Checking DeepHaloChoiceModel configuration and core hyperparameters\n",
      "\n",
      "[TEST] Verifying DeepHaloChoiceModel initializes and has core components\n",
      "\n",
      "[TEST] Checking that training reduces mse on toy data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/100 [00:00<?, ?it/s]2026-01-01 20:18:34.023411: I external/local_xla/xla/service/service.cc:168] XLA service 0x7d910c0ecb40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2026-01-01 20:18:34.023558: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3050 Laptop GPU, Compute Capability 8.6\n",
      "2026-01-01 20:18:34.043906: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2026-01-01 20:18:34.089923: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1767259114.160530   31066 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "Epoch 99 Train Loss 0.0000: 100%|█████████████████████████████████████████████████████| 100/100 [00:05<00:00, 17.24it/s]\n",
      ".WARNING:root:Some choices never happen in the dataset: {11, 3, 5}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[TEST] Checking that training reduces negative log-likelihood on toy data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99 Train Loss 0.0000: 100%|█████████████████████████████████████████████████████| 100/100 [00:05<00:00, 18.52it/s]\n",
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 12 tests in 15.958s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "def make_toy_dataset(B=16, J=5, F_item=4, F_shared=3, seed=42):\n",
    "    rng = np.random.RandomState(seed)\n",
    "\n",
    "    X_shared = rng.randn(B, F_shared).astype(np.float32)          # [B,F_shared]\n",
    "    X_items = rng.randn(B, J, F_item).astype(np.float32)          # [B,J,F_item]\n",
    "\n",
    "    A = (rng.rand(B, J) < 0.8).astype(np.float32)                 # [B,J]\n",
    "    A[(A.sum(axis=1) == 0), 0] = 1.0\n",
    "\n",
    "    w_item = rng.randn(F_item).astype(np.float32)\n",
    "    w_shared = rng.randn(F_shared).astype(np.float32)\n",
    "\n",
    "    util_items = np.tensordot(X_items, w_item, axes=([2], [0]))   # [B,J]\n",
    "    util_shared = (X_shared @ w_shared[:, None])                  # [B,1]\n",
    "    util = util_items + util_shared                               # [B,J]\n",
    "\n",
    "    util[A == 0] = -1e9\n",
    "    choices = util.argmax(axis=1).astype(np.int32)\n",
    "\n",
    "    return ChoiceDataset(\n",
    "        items_features_by_choice=X_items,\n",
    "        shared_features_by_choice=X_shared,\n",
    "        available_items_by_choice=A,\n",
    "        choices=choices,\n",
    "        items_features_by_choice_names=[f\"F_s{k}\" for k in range(X_items.shape[-1])],\n",
    "        shared_features_by_choice_names=[f\"F_i{k}\" for k in range(X_shared.shape[-1])]\n",
    "    )\n",
    "\n",
    "\n",
    "class TestDeepHaloChoiceModel(unittest.TestCase):\n",
    "\n",
    "    def setUp(self):\n",
    "        self.B, self.J = 16, 12\n",
    "        self.F_item, self.F_shared = 4, 3\n",
    "        self.dataset = make_toy_dataset(\n",
    "            B=self.B, J=self.J, F_item=self.F_item, F_shared=self.F_shared\n",
    "        )\n",
    "        self.model = DeepHaloChoiceModel(\n",
    "            H=7,\n",
    "            depth=3,\n",
    "            embed=16,\n",
    "            dropout=0.0,\n",
    "            lr=1e-3,\n",
    "            epochs=50,\n",
    "            batch_size=64,\n",
    "            featureless=False,\n",
    "            add_exit_choice=False,\n",
    "            optimizer=\"Adam\",\n",
    "            block_type=\"qua\",\n",
    "            loss_name=\"nll\",\n",
    "            feature2D= False,\n",
    "        )\n",
    "\n",
    "    def _get_batch(self):\n",
    "        idx = np.arange(self.B)\n",
    "        X_items = self.dataset.items_features_by_choice[0][idx]   # [B,J,F_item]\n",
    "        X_shared = self.dataset.shared_features_by_choice[0][idx] # [B,F_shared]\n",
    "        A = self.dataset.available_items_by_choice[idx]           # [B,J]\n",
    "        y = self.dataset.choices[idx]                             # [B]\n",
    "        return X_items, X_shared, A, y\n",
    "\n",
    "    # test inheritance\n",
    "    def test_inheritance_from_simple_mnl(self):\n",
    "        print(\"\\n[TEST] Checking that DeepHaloChoiceModel inherits from SimpleMNL\")\n",
    "        self.assertIsInstance(self.model, SimpleMNL)\n",
    "\n",
    "\n",
    "    \n",
    "    # test model initialization    \n",
    "    def test_model_initialization(self):\n",
    "        print(\"\\n[TEST] Verifying DeepHaloChoiceModel initializes and has core components\")\n",
    "        self.assertIsInstance(self.model, DeepHaloChoiceModel)\n",
    "        self.assertIsNotNone(self.model.deep_halo_core)\n",
    "        self.assertTrue(hasattr(self.model.deep_halo_core, \"init_encoder\"))\n",
    "        self.assertTrue(hasattr(self.model.deep_halo_core, \"aggregate_linear\"))\n",
    "        self.assertTrue(hasattr(self.model.deep_halo_core, \"nonlinear\"))\n",
    "\n",
    "    # test model configuration\n",
    "    def test_model_configuration(self):\n",
    "        print(\"\\n[TEST] Checking DeepHaloChoiceModel configuration and core hyperparameters\")\n",
    "        self.assertEqual(self.model.H, 7)\n",
    "        self.assertEqual(self.model.depth, 3)\n",
    "        self.assertEqual(self.model.embed, 16)\n",
    "        self.assertEqual(self.model.dropout, 0.0)\n",
    "        self.assertAlmostEqual(self.model.lr, 1e-3)\n",
    "        self.assertEqual(self.model.epochs, 50)\n",
    "        self.assertEqual(self.model.batch_size, 64)\n",
    "        self.assertFalse(self.model.featureless)\n",
    "        self.assertFalse(self.model.add_exit_choice)\n",
    "        self.assertEqual(self.model.optimizer_name, \"Adam\")\n",
    "        self.assertEqual(self.model.block_type, \"qua\")\n",
    "        self.assertEqual(self.model.loss_name, \"nll\")\n",
    "        self.assertFalse(self.model.feature2D)\n",
    "\n",
    "        core = self.model.deep_halo_core\n",
    "        self.assertEqual(core.H, 7)\n",
    "        self.assertEqual(core.embed, 16)\n",
    "        \n",
    "        # check the number of layers if equal to the depth\n",
    "        self.assertEqual(len(core.aggregate_linear), 3)\n",
    "        self.assertEqual(len(core.nonlinear), 3)\n",
    "\n",
    "    # test input / output shape and format\n",
    "    def test_input_output_shapes(self):\n",
    "        print(\"\\n[TEST] Checking input and output shapes/dtypes of compute_batch_utility\")\n",
    "        X_items, X_shared, A, y = self._get_batch()\n",
    "        logits = self.model.compute_batch_utility(\n",
    "            items_features_by_choice=X_items,\n",
    "            shared_features_by_choice=X_shared,\n",
    "            available_items_by_choice=A,\n",
    "            choices=y,\n",
    "        )\n",
    "        self.assertEqual(logits.shape, (self.B, self.J))\n",
    "        self.assertEqual(logits.dtype, tf.float32)\n",
    "\n",
    "\n",
    "        # test core type vs featureless flag\n",
    "    def test_core_type_matches_featureless_flag(self):\n",
    "        print(\"\\n[TEST] Checking core class matches featureless flag\")\n",
    "        model_feat = DeepHaloChoiceModel(featureless=False)\n",
    "        self.assertIsInstance(model_feat.deep_halo_core, DeepHaloFeatured)\n",
    "        model_fless3D = DeepHaloChoiceModel(featureless=True, embed=self.J)\n",
    "        self.assertIsInstance(model_fless3D.deep_halo_core, DeepHaloFeatureless3D)\n",
    "        model_fless2D = DeepHaloChoiceModel(featureless=True, feature2D=True, embed=self.J)\n",
    "        self.assertIsInstance(model_fless2D.deep_halo_core, DeepHaloFeatureless2D)\n",
    "\n",
    "        \n",
    "    # test X shape depends on featureless flag\n",
    "    def test_X_shape_depends_on_featureless_flag(self):\n",
    "        print(\"\\n[TEST] Checking X shape in compute_batch_utility for featureless vs featured\")\n",
    "\n",
    "        X_items, X_shared, A, y = self._get_batch()\n",
    "        \n",
    "        # featured: X should be 3D [B,J,D0]\n",
    "        # Here we assert that the object we pass is 3D.\n",
    "        self.assertEqual(len(X_items.shape), 3)\n",
    "        \n",
    "        model_feat = DeepHaloChoiceModel(featureless=False)                            \n",
    "        _ = model_feat.compute_batch_utility(\n",
    "            items_features_by_choice=X_items,\n",
    "            shared_features_by_choice=X_shared,\n",
    "            available_items_by_choice=A,\n",
    "            choices=y,\n",
    "        )\n",
    "\n",
    "        # featureless2D: X_items should be 2D  [B,D0] \n",
    "        # Here we assert that the object we pass is 2D.      \n",
    "        X_items_reduced = np.sum(X_items, axis=1)\n",
    "        self.assertEqual(len(X_items_reduced.shape), 2)\n",
    "        \n",
    "        model_fless = DeepHaloChoiceModel(featureless=True, feature2D=True, embed=self.J)\n",
    "        _ = model_fless.compute_batch_utility(\n",
    "            items_features_by_choice=X_items_reduced,\n",
    "            shared_features_by_choice=X_shared,\n",
    "            available_items_by_choice=A,\n",
    "            choices=y,\n",
    "        )\n",
    "\n",
    "    \n",
    "    # test output utilities with availability mask\n",
    "    def test_availability_mask_on_logits(self):\n",
    "        print(\"\\n[TEST] Verifying logits are masked (very negative) for unavailable items\")\n",
    "        X_items, X_shared, A, y = self._get_batch()\n",
    "        logits = self.model.compute_batch_utility(\n",
    "            items_features_by_choice=X_items,\n",
    "            shared_features_by_choice=X_shared,\n",
    "            available_items_by_choice=A,\n",
    "            choices=y,\n",
    "        )\n",
    "        mask_unavail = (A == 0)\n",
    "        masked_logits = tf.boolean_mask(logits, mask_unavail)\n",
    "        self.assertTrue(tf.reduce_all(masked_logits <= -1e8))\n",
    "        mask_avail = (A == 1)\n",
    "        avail_logits = tf.boolean_mask(logits, mask_avail)\n",
    "        self.assertTrue(tf.reduce_any(avail_logits > -1e8))\n",
    "\n",
    "    # test that training decreases NLL    \n",
    "    def test_training_decreases_nll(self):\n",
    "        print(\"\\n[TEST] Checking that training reduces negative log-likelihood on toy data\")\n",
    "        X_items, X_shared, A, y = self._get_batch()\n",
    "\n",
    "        def nll_from_logits(logits):\n",
    "            probs = tf.nn.softmax(logits, axis=-1)\n",
    "            y_oh = tf.one_hot(y, depth=probs.shape[1])\n",
    "            return -tf.reduce_mean(\n",
    "                tf.reduce_sum(y_oh * tf.math.log(probs + 1e-8), axis=-1)\n",
    "            )\n",
    "\n",
    "        logits0 = self.model.compute_batch_utility(\n",
    "            items_features_by_choice=X_items,\n",
    "            shared_features_by_choice=X_shared,\n",
    "            available_items_by_choice=A,\n",
    "            choices=y,\n",
    "        )\n",
    "        nll0 = float(nll_from_logits(logits0))\n",
    "        \n",
    "        \n",
    "        self.model.epochs = 100\n",
    "        self.model.fit(self.dataset)\n",
    "\n",
    "        logits1 = self.model.compute_batch_utility(\n",
    "            items_features_by_choice=X_items,\n",
    "            shared_features_by_choice=X_shared,\n",
    "            available_items_by_choice=A,\n",
    "            choices=y,\n",
    "        )\n",
    "        nll1 = float(nll_from_logits(logits1))\n",
    "\n",
    "        self.assertLessEqual(nll1, nll0)\n",
    "\n",
    "    # test that training decreases mse    \n",
    "    def test_training_decreases_mse(self):\n",
    "        print(\"\\n[TEST] Checking that training reduces mse on toy data\")\n",
    "        X_items, X_shared, A, y = self._get_batch()\n",
    "\n",
    "        def mse_from_logits(logits):\n",
    "            probs = tf.nn.softmax(logits, axis=-1)\n",
    "            y_oh = tf.one_hot(y, depth=probs.shape[1])\n",
    "            return tf.reduce_mean(\n",
    "                tf.reduce_sum((y_oh - probs)**2, axis=-1), axis=-1)\n",
    "            \n",
    "\n",
    "        mse_model = DeepHaloChoiceModel(\n",
    "            H=7,\n",
    "            depth=3,\n",
    "            embed=16,\n",
    "            dropout=0.0,\n",
    "            lr=1e-3,\n",
    "            epochs=100,\n",
    "            batch_size=self.B,\n",
    "            featureless=False,\n",
    "            add_exit_choice=False,\n",
    "            optimizer=\"Adam\",\n",
    "            block_type=\"qua\",\n",
    "            loss_name=\"mse\",\n",
    "            feature2D=False,\n",
    "        )\n",
    "\n",
    "        assert isinstance(mse_model.loss, tf.keras.losses.MeanSquaredError)\n",
    "\n",
    "        logits0 = mse_model.compute_batch_utility(\n",
    "            items_features_by_choice=X_items,\n",
    "            shared_features_by_choice=X_shared,\n",
    "            available_items_by_choice=A,\n",
    "            choices=y,\n",
    "        )\n",
    "        mse0 = float(mse_from_logits(logits0))\n",
    "\n",
    "        mse_model.fit(self.dataset)\n",
    "\n",
    "        logits1 = mse_model.compute_batch_utility(\n",
    "            items_features_by_choice=X_items,\n",
    "            shared_features_by_choice=X_shared,\n",
    "            available_items_by_choice=A,\n",
    "            choices=y,\n",
    "        )\n",
    "        mse1 = float(mse_from_logits(logits1))\n",
    "\n",
    "        self.assertLessEqual(mse1, mse0)\n",
    "\n",
    "    # test equivariance in featured setting\n",
    "    def test_equivariance_under_item_permutation_featured(self):\n",
    "        print(\"\\n[TEST] Checking permutation equivariance for featured DeepHaloChoiceModel\")\n",
    "        model = DeepHaloChoiceModel(\n",
    "            H=7,\n",
    "            depth=3,\n",
    "            embed=16,\n",
    "            dropout=0.0,\n",
    "            lr=1e-3,\n",
    "            epochs=10,\n",
    "            batch_size=self.B,\n",
    "            featureless=False,\n",
    "            add_exit_choice=False,\n",
    "            optimizer=\"Adam\",\n",
    "            block_type=\"qua\",\n",
    "            loss_name=\"nll\",\n",
    "            feature2D=False,\n",
    "        )\n",
    "\n",
    "        X_items, X_shared, A, y = self._get_batch()   # X_items: [B,J,D0]  # X_shared: [B,F0]\n",
    "\n",
    "        logits = model.compute_batch_utility(\n",
    "            items_features_by_choice=X_items,\n",
    "            shared_features_by_choice=X_shared,\n",
    "            available_items_by_choice=A,\n",
    "            choices=y,\n",
    "        )                                             # [B,J]\n",
    "\n",
    "        perm = np.random.permutation(self.J)          # [J]\n",
    "        inv_perm = np.argsort(perm)\n",
    "        inv_perm_tf = tf.convert_to_tensor(inv_perm, dtype=tf.int32)\n",
    "\n",
    "        X_items_perm = X_items[:, perm, :]            # [B,J,D0]\n",
    "        A_perm = A[:, perm]\n",
    "\n",
    "        logits_perm = model.compute_batch_utility(\n",
    "            items_features_by_choice=X_items_perm,\n",
    "            shared_features_by_choice=X_shared,\n",
    "            available_items_by_choice=A_perm,\n",
    "            choices=y,\n",
    "        )                                             # [B,J]\n",
    "\n",
    "        # undo permutation using tf.gather\n",
    "        logits_perm_unperm = tf.gather(logits_perm, inv_perm_tf, axis=1)\n",
    "\n",
    "        max_diff = tf.reduce_max(tf.abs(logits - logits_perm_unperm))\n",
    "        self.assertLess(float(max_diff), 1e-5)\n",
    "\n",
    "\n",
    "\n",
    "    # test equivariance in 3D featureless setting\n",
    "    def test_equivariance_under_item_permutation_featureless3D(self):\n",
    "        print(\"\\n[TEST] Checking permutation equivariance for 3D featureless DeepHaloChoiceModel\")\n",
    "        model = DeepHaloChoiceModel(\n",
    "            H=7,\n",
    "            depth=3,\n",
    "            embed=self.J,\n",
    "            dropout=0.0,\n",
    "            lr=1e-3,\n",
    "            epochs=10,\n",
    "            batch_size=self.B,\n",
    "            featureless=True,\n",
    "            add_exit_choice=False,\n",
    "            optimizer=\"Adam\",\n",
    "            block_type=\"qua\",\n",
    "            loss_name=\"nll\",\n",
    "            feature2D=False,\n",
    "        )\n",
    "\n",
    "        X_items, X_shared, A, y = self._get_batch()   # X_items: [B,J,D0]  # X_shared: [B,F0]\n",
    "        X_items = np.tile(np.eye(self.J)[None, ...], (A.shape[0], 1, 1))  # replace items features with one-hot embeddings\n",
    "\n",
    "        logits = model.compute_batch_utility(\n",
    "            items_features_by_choice=X_items,\n",
    "            shared_features_by_choice=X_shared,\n",
    "            available_items_by_choice=A,\n",
    "            choices=y,\n",
    "        )                                             # [B,J]\n",
    "\n",
    "        perm = np.random.permutation(self.J)          # [J]\n",
    "        inv_perm = np.argsort(perm)\n",
    "        inv_perm_tf = tf.convert_to_tensor(inv_perm, dtype=tf.int32)\n",
    "\n",
    "        X_items_perm = X_items[:, perm, :]            # [B,J,D0]\n",
    "        A_perm = A[:, perm]\n",
    "\n",
    "        logits_perm = model.compute_batch_utility(    # [B,J]\n",
    "            items_features_by_choice=X_items_perm,\n",
    "            shared_features_by_choice=X_shared,\n",
    "            available_items_by_choice=A_perm,\n",
    "            choices=y,\n",
    "        )                                             \n",
    "\n",
    "        # undo permutation using tf.gather\n",
    "        logits_perm_unperm = tf.gather(logits_perm, inv_perm_tf, axis=1)\n",
    "\n",
    "        max_diff = tf.reduce_max(tf.abs(logits - logits_perm_unperm))\n",
    "        self.assertLess(float(max_diff), 1e-5)\n",
    "        \n",
    "    # test invariance (different from equivariance) in 2D featureless setting\n",
    "    def test_invariance_under_item_permutation_featureless2D(self):\n",
    "        print(\"\\n[TEST] Checking permutation invariance for 2D featureless DeepHaloChoiceModel\")\n",
    "        model = DeepHaloChoiceModel(\n",
    "            H=7,\n",
    "            depth=3,\n",
    "            embed=self.J,\n",
    "            dropout=0.0,\n",
    "            lr=1e-3,\n",
    "            epochs=10,\n",
    "            batch_size=self.B,\n",
    "            featureless=True,\n",
    "            add_exit_choice=False,\n",
    "            optimizer=\"Adam\",\n",
    "            block_type=\"qua\",\n",
    "            loss_name=\"nll\",\n",
    "            feature2D=True,\n",
    "        )\n",
    "\n",
    "        X_items, X_shared, A, y = self._get_batch()   # X_items: [B,J,D0]  # X_shared: [B,F0]\n",
    "        X_items = np.tile(np.eye(self.J)[None, ...], (A.shape[0], 1, 1))  # replace items features with one-hot embeddings\n",
    "\n",
    "        logits = model.compute_batch_utility(\n",
    "            items_features_by_choice=X_items,\n",
    "            shared_features_by_choice=X_shared,\n",
    "            available_items_by_choice=A,\n",
    "            choices=y,\n",
    "        )                                             # [B,J]\n",
    "\n",
    "        perm = np.random.permutation(self.J)          # [J]\n",
    "        inv_perm = np.argsort(perm)\n",
    "        inv_perm_tf = tf.convert_to_tensor(inv_perm, dtype=tf.int32)\n",
    "\n",
    "        X_items_perm = X_items[:, perm, :]            # [B,J,D0]\n",
    "        A_perm = A[:, perm]\n",
    "\n",
    "        logits_perm = model.compute_batch_utility(\n",
    "            items_features_by_choice=X_items_perm,\n",
    "            shared_features_by_choice=X_shared,\n",
    "            available_items_by_choice=A_perm,\n",
    "            choices=y,\n",
    "        )                                            \n",
    "\n",
    "    \n",
    "        logits_diff = logits - logits_perm\n",
    "        logits_diff_masked = logits_diff*A_perm*A   # only compare on common available indices in A and A_perm: if they are the same, then invariance holds\n",
    "        \n",
    "        max_diff = tf.reduce_max(tf.abs(logits_diff_masked))\n",
    "        self.assertLess(float(max_diff), 1e-5)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    unittest.main(argv=[\"first-arg-is-ignored\"], exit=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccd5c07-7e33-46d4-8959-251a633909da",
   "metadata": {},
   "source": [
    "You can alternatively run the following script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52960577-899e-49de-bd99-c7a0d360a6d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-01 20:18:43.643352: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2026-01-01 20:18:43.643451: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2026-01-01 20:18:43.645342: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2026-01-01 20:18:43.653092: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2026-01-01 20:18:44.373541: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2026-01-01 20:18:45.263593: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2026-01-01 20:18:45.350200: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2026-01-01 20:18:45.350326: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "Initializing DeepHaloChoiceModel package v1.0.0\n",
      "/root/miniconda3/envs/tf/lib/python3.10/runpy.py:126: RuntimeWarning: 'tests.DeepHalo_Tests' found in sys.modules after import of package 'tests', but prior to execution of 'tests.DeepHalo_Tests'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "test_X_shape_depends_on_featureless_flag (__main__.TestDeepHaloChoiceModel) ... WARNING:root:Some choices never happen in the dataset: {11, 3, 5}\n",
      "2026-01-01 20:18:45.358668: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2026-01-01 20:18:45.358799: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2026-01-01 20:18:45.358877: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2026-01-01 20:18:45.565168: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2026-01-01 20:18:45.565301: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2026-01-01 20:18:45.565350: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2026-01-01 20:18:45.565460: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2026-01-01 20:18:45.565529: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1766 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "\n",
      "[TEST] Checking X shape in compute_batch_utility for featureless vs featured\n",
      "2026-01-01 20:18:45.913533: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "ok\n",
      "test_availability_mask_on_logits (__main__.TestDeepHaloChoiceModel) ... WARNING:root:Some choices never happen in the dataset: {11, 3, 5}\n",
      "\n",
      "[TEST] Verifying logits are masked (very negative) for unavailable items\n",
      "ok\n",
      "test_core_type_matches_featureless_flag (__main__.TestDeepHaloChoiceModel) ... WARNING:root:Some choices never happen in the dataset: {11, 3, 5}\n",
      "\n",
      "[TEST] Checking core class matches featureless flag\n",
      "ok\n",
      "test_equivariance_under_item_permutation_featured (__main__.TestDeepHaloChoiceModel) ... WARNING:root:Some choices never happen in the dataset: {11, 3, 5}\n",
      "\n",
      "[TEST] Checking permutation equivariance for featured DeepHaloChoiceModel\n",
      "ok\n",
      "test_equivariance_under_item_permutation_featureless3D (__main__.TestDeepHaloChoiceModel) ... WARNING:root:Some choices never happen in the dataset: {11, 3, 5}\n",
      "\n",
      "[TEST] Checking permutation equivariance for 3D featureless DeepHaloChoiceModel\n",
      "ok\n",
      "test_inheritance_from_simple_mnl (__main__.TestDeepHaloChoiceModel) ... WARNING:root:Some choices never happen in the dataset: {11, 3, 5}\n",
      "\n",
      "[TEST] Checking that DeepHaloChoiceModel inherits from SimpleMNL\n",
      "ok\n",
      "test_input_output_shapes (__main__.TestDeepHaloChoiceModel) ... WARNING:root:Some choices never happen in the dataset: {11, 3, 5}\n",
      "\n",
      "[TEST] Checking input and output shapes/dtypes of compute_batch_utility\n",
      "ok\n",
      "test_invariance_under_item_permutation_featureless2D (__main__.TestDeepHaloChoiceModel) ... WARNING:root:Some choices never happen in the dataset: {11, 3, 5}\n",
      "\n",
      "[TEST] Checking permutation invariance for 2D featureless DeepHaloChoiceModel\n",
      "ok\n",
      "test_model_configuration (__main__.TestDeepHaloChoiceModel) ... WARNING:root:Some choices never happen in the dataset: {11, 3, 5}\n",
      "\n",
      "[TEST] Checking DeepHaloChoiceModel configuration and core hyperparameters\n",
      "ok\n",
      "test_model_initialization (__main__.TestDeepHaloChoiceModel) ... WARNING:root:Some choices never happen in the dataset: {11, 3, 5}\n",
      "\n",
      "[TEST] Verifying DeepHaloChoiceModel initializes and has core components\n",
      "ok\n",
      "test_training_decreases_mse (__main__.TestDeepHaloChoiceModel) ... WARNING:root:Some choices never happen in the dataset: {11, 3, 5}\n",
      "\n",
      "[TEST] Checking that training reduces mse on toy data\n",
      "  0%|                                                   | 0/100 [00:00<?, ?it/s]2026-01-01 20:18:50.586202: I external/local_xla/xla/service/service.cc:168] XLA service 0x768740146e80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2026-01-01 20:18:50.586282: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3050 Laptop GPU, Compute Capability 8.6\n",
      "2026-01-01 20:18:50.592518: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2026-01-01 20:18:50.610456: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1767259130.676975   31492 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "Epoch 99 Train Loss 0.0078: 100%|█████████████| 100/100 [00:05<00:00, 17.91it/s]\n",
      "ok\n",
      "test_training_decreases_nll (__main__.TestDeepHaloChoiceModel) ... WARNING:root:Some choices never happen in the dataset: {11, 3, 5}\n",
      "\n",
      "[TEST] Checking that training reduces negative log-likelihood on toy data\n",
      "Epoch 99 Train Loss 0.0000: 100%|█████████████| 100/100 [00:04<00:00, 20.01it/s]\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 12 tests in 13.793s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!python  -m tests.DeepHalo_Tests -v"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
